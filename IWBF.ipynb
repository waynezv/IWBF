{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech latent feature discovery for multi-label forensic profiling\n",
    "\n",
    "Project for IWBF 2018\n",
    "\n",
    "----\n",
    "\n",
    "**Objective:** Find latent representations in speech that can predict forensic aspects of human.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update ~12/11/2017\n",
    "\n",
    "1. Write-up:\n",
    "\n",
    "    https://www.overleaf.com/12702004wrrmdybmpqsq#/48448185/\n",
    "\n",
    "2. Implementation\n",
    "    1. Data: TIMIT, Alcohol, (SRE)\n",
    "    2. Model\n",
    "        ![model](./write-up/figs/model.png)  \n",
    "    3. Current attributes: speaker-id, gender, dialect, age, height, drunk\n",
    "    4. [Code](./src)\n",
    "    \n",
    "3. Final poster for convex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update ~12/18/2017\n",
    "\n",
    "1. Experiments\n",
    "    1. Currently using latent codes from autoencoder to do multi-label classification and regression.\n",
    "    2. It works well on certain tasks (gender, dialect, height), but not well on other tasks (id, age).\n",
    "    3. Including more datasets (SRE, Yandong's face data)\n",
    "\n",
    "\n",
    "|Label | Reconstruction Loss ($l_2^2$) | ID Acc (%) | Gender Acc (%) | Dialect Acc (%) | Age MSE | Height MSE |\n",
    "|:----|----:|---:|---:|---:|----:|---:|\n",
    "| Train | 0.8565 | 75.15 | 96.15 | 89.40 | 4.5411 | 0.1634 |\n",
    "| Test | 2.2059 | 66.15 | 92.15 | 83.17  | 5.1525 | 0.2353 |\n",
    "\n",
    " \n",
    "2. Writing paper\n",
    "\n",
    "3. Todo next week\n",
    "    1. Finish draft of the paper.\n",
    "    2. Improve the model.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update ~12/19/2017\n",
    "\n",
    "1. Experiments\n",
    "    1. Observations: ID, Age and Dialect seem to be correlated (similar trends of loss), whereas Gender and Height seem to be independent (not speaker-dependent).\n",
    "    2. Back to closed set of speakers -- openset is far more difficult.\n",
    "    3. Reduce model size to speed up training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
